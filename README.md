# LLMArxivTalk
최신 LLM 관련 스터디. 기본 오후에 진행. 논문, 강의, 코드, 뉴스, 블로그 등 다양한 자료로 학습.

LLM, NLG, Dialogue, Reinforcement learning, Distillation, Efficient, Sentence similarity, multiple tasks, multimodal, Stable diffusion, TTS, Text-To-Video, All-To-All, 우주, 생명, 지능, 윤리, 규제, 법, 노화, 의학, 투자, 개발, 인프라, 디자인, 경영, ETC... 

유망 스타트업 C레벨, 국내외 탑티어 연구자, 국내외 탑티어 대학, 대학원 재학생과 졸업생, 석학, 교수 등 **A급 인재들이 최신 논문, 강의 등 스터디 및 프로젝트 진행.**

기본 매주 수요일 오후 7시반. 사전 학습 없이 논문 읽기 최대 20분, 토론 최대 40분. 한 번에 1 ~ 10개 논문, 강의 등 진행. 지금까지는 항상 3개. 주제 논문 선정은 자유. 탑티어 학회 논문 및 프로젝트 제작 예정.

주말을 포함하여, 거의 매일 추가 스터디 존재. 흥미로운 주제거나 참여 되는 날만 중간에 들어와서 중간에 나가도 무관. 모든 규칙은 협의 가능. 오프라인 모임도 예정. 자율 참여.

## 진행 사항 + 예정
2023-02-16 23:30 ~ 24:45 염기웅, 강수진, 고현웅
- [GPT Understands, To](https://arxiv.org/pdf/2103.10385.pdf)
- [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/abs/2110.07602.pdf)
- [Do Prompt-Based Models Really Understand the Meaning of their Prompts?](https://arxiv.org/pdf/2109.01247.pdf)

2023-02-19 23:30 ~ 24:30 염기웅, 박상준, 강수진
- [∞-former: Infinite Memory Transformer](https://arxiv.org/abs/2109.00301)
- [Improving language models by retrieving from trillions of tokens](https://arxiv.org/pdf/2112.04426.pdf)
- [Augmented Language Models: a Survey](https://arxiv.org/pdf/2302.07842.pdf)

2023-02-22 19:30 ~ 21:00 염기웅, 박상준, 이웅기, 이현제
- [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/pdf/2301.12597v1.pdf)
- [Structure and Content-Guided Video Synthesis with Diffusion Models](https://arxiv.org/pdf/2302.03011.pdf)
- [MusicLM: Generating Music From Text](https://arxiv.org/pdf/2301.11325.pdf)

2023-02-23 23:00 ~ 24:00 염기웅, 박상준, 황명하
- [InstructGPT : Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)
- [BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining](https://arxiv.org/abs/2210.10341)

2023-02-24 17:00 ~ 19:00 염기웅
- [Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862)
- [Multimodal Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2302.00923)
- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)
- [Provable Copyright Protection for Generative Models](https://arxiv.org/abs/2302.10870)
- [What learning algorithm is in-context learning? Investigations with linear models](https://arxiv.org/abs/2211.15661)
- [A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)
- [PAL: Program-aided Language Models](https://arxiv.org/pdf/2211.10435.pdf)
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761.pdf)

2023-03-01 20:30 ~ 21:40 염기웅, 이대환
- [LLaMA: Open and Efficient Foundation Language Models](https://research.facebook.com/file/1574548786327032/LLaMA--Open-and-Efficient-Foundation-Language-Models.pdf)
- [Improving alignment of dialogue agents via targeted human judgements](https://arxiv.org/pdf/2209.14375.pdf)
- [Training Compute-Optimal Large Language Models](https://arxiv.org/pdf/2203.15556.pdf)

2023-03-04 22:00 ~ 23:30 염기웅, 황명하
- [LLaMA-based ChatGPT training](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama), [ChatLLaMA](https://github.com/juncongmoo/chatllama)
- [RLHF: Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/pdf/2204.05862.pdf)
- [BaGuaLu: Targeting Brain Scale Pretrained Models with over 37 Million Cores](https://dl.acm.org/doi/pdf/10.1145/3503221.3508417)

2023-03-05 21:00 ~ 21:30 염기웅, 
- [LLaMA-7B](https://huggingface.co/spaces/chansung/LLaMA-7B), [LLAMA Up-data](https://github.com/hunkim/llama-up-data), [LLaMA: INT8 edition](https://github.com/tloen/llama-int8), [UForm](https://github.com/unum-cloud/uform)

2023-03-07 00:00 ~ 01:00 염기웅, 김미담, 
- [Language Is Not All You Need: Aligning Perception with Language Models](https://arxiv.org/pdf/2302.14045v1.pdf)
- [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198), [Blog](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model)
- [Multimodal Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2302.00923)

2023-03-08 19:30 ~ 20:30 염기웅, 
- [SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks](https://arxiv.org/abs/2302.13939)
- [PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311)
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf)
- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)
- [Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning](https://github.com/cloneofsimo/lora)
- [huggingface-projects/diffusers-gallery](https://huggingface.co/spaces/huggingface-projects/diffusers-gallery)
- [huggingface-projects/diffusers-gallery-bot](https://huggingface.co/spaces/huggingface-projects/diffusers-gallery-bot)

## 규칙
1. 영어만 사용은 금지. 한국어 중심 사용. 특수 용어는 영어 사용.
2. 1주일에 논문 2개 이상 스터디. 되는 사람은 10개 이상.
3. 3분에서 20분 현장에서 논문 읽기. 5분에서 30분 토론.
4. 1시간 스터디 시, 바로 나가도 됨. 원할 때 10분 이하 참여도 무관. 자유롭게 진행. 2시간 매일도 가능.
5. 각자 더 뛰어난 게 있다는 것을 인지. 다들 대단한 분들이니 질문 많이 하고, 정보 공유 자주.
6. 본인이 하기로 한 일만은 수행. 한다고 말하고, 안 하는 것은 민폐다.
7. 기본적으로 녹화 후 내부 공유.
8. 정보를 혼자 알게 쓰지 말고, 다 같이 알게 말하기.
9. 개인 사정으로 스터디 탈퇴 시, 자기소개에 인사 작성.
10. 여러 기관 좋은 규칙 붙여넣기.
11. 팀에 도움이 된다고 판단하면, 위 규칙을 모두 무시하고 행동.
12. 추가.

## 후보
앞으로 할만한 논문, 코드, 강의 등.

### papaer
- [Improving language models by retrieving from trillions of tokens](https://arxiv.org/pdf/2112.04426.pdf)
- [FLAN: Finetuned Language Models Are Zero-Shot Learners](https://arxiv.org/abs/2109.01652.pdf)
- [T0: Multitask Prompted Training Enables Zero-Shot Task Generalization](https://arxiv.org/abs/2110.08207.pdf)
- [The Flan Collection: Designing Data and Methods for Effective Instruction Tuning](https://arxiv.org/abs/2301.13688.pdf)
- [The Wisdom of Hindsight Makes Language Models Better Instruction Followers](https://arxiv.org/abs/2302.05206.pdf)
- [Exploring the Benefits of Training Expert Language Models over Instruction Tuning](https://paperswithcode.com/paper/exploring-the-benefits-of-training-expert.pdf)
- [Unsupervised Imputation of Non-ignorably Missing Data Using Importance-Weighted Autoencoders](https://arxiv.org/abs/2101.07357)
- [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/abs/2104.08691)
- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073.pdf)
- [Deep reinforcement learning from human preferences](https://arxiv.org/abs/1706.03741.pdf)
- [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961.pdf)
- [Large Language Models with Controllable Working Memory](https://arxiv.org/abs/2211.05110.pdf)
- [Do Prompt-Based Models Really Understand the Meaning of their Prompts?](https://arxiv.org/abs/2109.01247.pdf)
- [Muse: Text-To-Image Generation via Masked Generative Transformers](https://arxiv.org/pdf/2301.00704v1.pdf)
- [Structure and Content-Guided Video Synthesis with Diffusion Models](https://arxiv.org/abs/2302.03011.pdf)
- [Generative Pretraining from Pixels](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)
- [A hunt for the Snark: Annotator Diversity in Data Practices](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/c5dbc2c146b7443447d43a344b4a22a359b32b16.pdf)
- [Accurate global machine learning force fields for molecules with hundreds of atoms](https://www.science.org/doi/full/10.1126/sciadv.adf0873)
- [Algorithms with More Granular Differential Privacy Guarantees](https://arxiv.org/pdf/2209.04053.pdf)
- [Anomaly Clustering: Grouping Images into Coherent Clusters of Anomaly Types](https://research.google/pubs/pub51881/)
- [Are we cobblers without shoes? Making Computer Science data FAIR](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/962979aa7d369692aa1919dcb517a5e5a3d0fa66.pdf)
- [Code Generation for In-Place Stencils](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/26cdf8c85c428bbff96ff6e7a07fe313e9844d68.pdf)
- [Creating, Calibrating, and Validating Large-Scale Microscopic Traffic Simulation](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/0e0284222cf7d2d690f1b277b970de8e3f61294a.pdf)
- [Increasing Impact of Mobile Health Programs: SAHELI for Maternal and Child Care](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/4e67c21de7542a2eb61edd37ece44c86928e00b1.pdf)
- [Designing Responsible AI: Adaptations of UX Practice to Meet Responsible AI Challenges](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/4045f0e0e61d89b6b1eacad4b861e86631d5e660.pdf)
- [Developer Productivity for Humans: A Human-Centered Approach to Developer Productivity](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9994260)
- [Development of a Machine Learning Model for Sonographic Assessment of Gestational Age](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2800007)
- [Drug Design on Quantum Computers](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/20b69430c8fd64f170d5c7ba0a0535aa51e70ab6.pdf)
- [Estimates of broadband upwelling irradiance from GOES-16 ABI](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/146e5813afdf4f8ba02d18a801c6ed06de27d7d5.pdf)
- [Information Processing and Management](https://reader.elsevier.com/reader/sd/pii/S0306457322003508?token=D58C3F3F1C12E28D51A5515FA2F3608D25FB798EBDEE89D440A941BFCFAC8872866F56B9D4B863D69728CCCB26963764&originRegion=us-east-1&originCreation=20230216172152)
- [Flake Aware Culprit Finding](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/a422ac172dbb3c6521f2bc6c83d363695f4e911c.pdf)
- [Flexible Budgets in Restless Bandits: A Primal-Dual Algorithm for Efficient Budget Allocation](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/00074e5dacad1fe2e7f03f65274993fcfbc860bd.pdf)
- [Helpful Neighbors: Leveraging Neighbors in Geographic Feature Pronunciation](https://watermark.silverchair.com/tacl_a_00535.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr0wggK5BgkqhkiG9w0BBwagggKqMIICpgIBADCCAp8GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMGaBmgqnePMpUEr_1AgEQgIICcHADbjfmiT9rEwbAOxm_3_0F7rZ2w_ETcJECYlEEpAHZUqPFKMP6eae59zDGkfZVaF3pq7w2JGFl-PJqQyT_fdQxIadVrVhW-xsibjoGYmAnciIFFIedkpSKJqXP2k4KG-lrRck9cEprUnptSHqq_VHWZFCETv1b9EuexXPfjHGEYDVCFEHER2nfwGzp4E7iMMvlOm53M3gU_WUmXcJOZcAnOgmYCyNh01R7f3vzI4Y1zKz9lhGNTL86mU-wFv-8aUWWbtIFLoiCgGaAgmp3m5N-vmefhqL4UtutrkAfTwq0xxg6VmEoSpBk52mIBusp07qxFA8s0wXFu3mBkJLJAVFqLtBJsyl2jic59TmHY4BDt7An6WcozDInnxILNbClDQAqVIh6OLNOJ4r9MXFUAyTrX3lbqN52SlygwV4K3z_ZFdGM7ndaWuJg5Ou2UdXfnaFrSjyvcNRutcUaupT7DGcXV3L7wb7b-XKA4OoAdSS8x1s-hhNW4l-I_iuiTx5vRAsVY0EyhOR2EPajiLKiEVN7SDEZ9ihAtef312FBsqu9xK10m14chdHdxvuIrwtuBwcVaj1rMPIzRPLU_l3Hxfa2x735pDjHZhDxzm2rEyXtlOXY-VIiv2gXD539gB1KFQ3VCjVnvOsesXlMue9a0LPPU6Tyb7wpo43ERNs8U5s5BRmomjOsUMyeM_Zp47O94WNyMo6V_F2bjhEZJq-lJZxtyqGcN6QFXiSdGoMIG5xQasrVUButsE3tVJELEjZU_j5rRKt8iXYPvRXsCNHZWG0_ezt_NsHM6H9xgz6vTFtezIGiLmpYZIBcVcU51Iq5bw)
- [High-Performance GPU-to-CPU Transpilation and Optimization via High-Level Parallel Constructs](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/ca9caaef5f92cb1c1088897a9654a79ccdcb2bd4.pdf)
- [Helpful Neighbors: Leveraging Neighbors in Geographic Feature Pronunciation](https://watermark.silverchair.com/tacl_a_00535.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr0wggK5BgkqhkiG9w0BBwagggKqMIICpgIBADCCAp8GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM9k6JNPdG5DftjzF0AgEQgIICcAmosEi5f1ji5KSTr9mz9ZwOEdbRU73_HgVTuXYzZyu500yymmCBEL9V1rg0Dv6ynhoWfTZJIozQ8Qd30uTpLwf5N167hksw3DLEAIsOMG4zoYFts1uazpEn42BVoQANpM-xj9ruJM5YQuYWscLrXzmCGAI93pQSxPlkjiwPQtsUlX713I5Qn_QDaV8_sGTMu0yw_Dxbz9p5dtFy_wovYDhzCB4W7yQlEaVhFUvk04A3PEfVmIi2c0sctYptcz8QDEnPI-kGpD_mplO65b0QHmYYBWriZWc13d4M6RyUWAgrpMQinmZtFRSxYjBof-BoqnlLEMpxfMECrFRTK3Jx3sKfWPpEfye_VpcJ4b-PqDpCHuMnjSL2jqmcRN5Fp9vhyjECs7HMepK618KC8NAJRN4_YbQnyOm-UT5MzaL72aQsaChkr1xZi9JOUe1xvqdjazEH9y9VgvW7cM8XCZZVLum87s2zsx8qzjqPMsfZLRoc8HsB9Tu-dvuxGPQK3gKetGRQjatjbKn4a3CSWhAij5ayG66Aa4AaYi-33iqG4EcBH6WLQG9JouFiojC1Pkj03O0evnvXP1zy11CZ_3w9QjScEfXdUh3no0dukyw5pnsrlxDWdGhZZFQx1NfGcYDOi6luzEpAijwKIVm7FogdhVg_hD63JoddNI9y7iTESYBvkBwt249qyhnpJ2Z5osFuipKGyOEYog0DYh1jxY-BIu1CY-vb9uLr1Jud7zCXkIwxfYswmLXiaJJQQo3v6Rle5Wek3MxP4CN4X4mwtQrrFJFKwddfMa6Ki5ViOTS-ckW_zLoNaORYu8UKfz_2fPjxNg)
- [Infrastructuring Care: How Trans and Non-Binary People Meet Health and Well-Being Needs through Technology](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/98030d5f96d6f383c90e40fcbf79425919f178d3.pdf)
- [KwikBucks: Correlation Clustering with Cheap-Weak and Expensive-Strong Signals](https://openreview.net/pdf?id=p0JSSa1AuV)
- [Learning to Bid in Contextual First Price Auctions](https://arxiv.org/pdf/2109.03173.pdf)
- [Machine Learning for Healthcare: A Bibliometric Study of Contributions from Africa](https://www.preprints.org/manuscript/202302.0010/v1)
- [Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/c394143cc1cb501f710a304f15983e70ed22fa8a.pdf)
- [Robust Planning over Restless Groups: Engagement Interventions for a Large-Scale Maternal Telehealth Program](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/c3043326e08d5775bc766ab494254e02560cfbe0.pdf)
- [Recitation-Augmented Language Models](https://arxiv.org/pdf/2210.01296.pdf)
- [RL4ReAl: Reinforcement Learning for Register Allocation](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/cfad891e4eee1a4c38f55bff5117b3ba7aa65392.pdf)
- [Quantum Simulation of Exact Electron Dynamics can be more Efficient than Classical Mean-Field Methods](https://research.google/pubs/pub52012/)
- [Quantum simulation of exact electron dynamics can be more efficient than classical mean-field methods](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/231543ccbbbd24d725563e79c01743fbb4eb06e0.pdf)
- [Propeller: A Profile Guided, Relinking Optimizer for Warehouse-Scale Applications](https://dl.acm.org/doi/10.1145/3575693.3575727)
- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916.pdf%EC%97%90%EC%84%9C)


- [Deepmind: Improving language models by retrieving from trillions of tokens](https://www.deepmind.com/publications/improving-language-models-by-retrieving-from-trillions-of-tokens)
- [Deepmind: Building safer dialogue agents](https://www.deepmind.com/blog/building-safer-dialogue-agents)
- [Deepmind: Competitive programming with AlphaCode](https://www.deepmind.com/blog/competitive-programming-with-alphacode)
- [Deepmind: Mastering Stratego, the classic game of imperfect information](https://www.deepmind.com/blog/mastering-stratego-the-classic-game-of-imperfect-information)
- [Deepmind: DeepMind’s latest research at NeurIPS 2022](https://www.deepmind.com/blog/deepminds-latest-research-at-neurips-2022)
- [Deepmind: Building interactive agents in video game worlds](https://www.deepmind.com/blog/building-interactive-agents-in-video-game-worlds)
- [Deepmind: Discovering novel algorithms with AlphaTensor](https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor)
- [Deepmind: AlphaFold reveals the structure of the protein universe](https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe)
- [Deepmind: Tackling multiple tasks with a single visual language model](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model)
- [Deepmind: Exploring the beauty of pure mathematics in novel ways](https://www.deepmind.com/blog/exploring-the-beauty-of-pure-mathematics-in-novel-ways)
- [Deepmind: Nowcasting the next hour of rain](https://www.deepmind.com/blog/nowcasting-the-next-hour-of-rain)
- [Deepmind: Putting the power of AlphaFold into the world’s hands](https://www.deepmind.com/blog/putting-the-power-of-alphafold-into-the-worlds-hands)
- [Google Research: Deciphering clinical abbreviations with privacy protecting ML](https://ai.googleblog.com/2023/01/deciphering-clinical-abbreviations-with.html)
- [Google Research: Google Research, 2022 & beyond: Language, vision and generative models](https://ai.googleblog.com/2023/01/google-research-2022-beyond-language.html)
- [Google Research: Google Research, 2022 & beyond: Responsible AI](https://ai.googleblog.com/2023/01/google-research-2022-beyond-responsible.html)
- [Google Research: Learning with queried hints](https://ai.googleblog.com/2023/01/learning-with-queried-hints.html)
- [Google Research: Open Source Vizier: Towards reliable and flexible hyperparameter and blackbox optimization](https://ai.googleblog.com/2023/02/open-source-vizier-towards-reliable-and.html)
- [Google Research: Google Research, 2022 & beyond: ML & computer systems](https://ai.googleblog.com/2023/02/google-research-2022-beyond-ml-computer.html)
- [Google Research: Real-time tracking of wildfire boundaries using satellite imagery](https://ai.googleblog.com/2023/02/real-time-tracking-of-wildfire.html)
- [Google Research: Breaching the 2 LMP Approximation Barrier for Facility Location with Applications to k-Median](https://research.google/pubs/pub51938/)
- [Google Research: Chimane-Mosetén](https://research.google/pubs/pub52097/)
- [Google Research: Differentially Private All-Pairs Shortest Path Distances: Improved Algorithms and Lower Bounds](https://research.google/pubs/pub51926/)
- [Google Research: Differentially Private Fair Division](https://research.google/pubs/pub51931/)
- [Google Research: DiffQG: Generating Questions on Paired Sentences](https://research.google/pubs/pub52078/)
- [Google Research: Assessment of Security Defense of Native Programs Against Software Faults](https://link.springer.com/chapter/10.1007/978-3-031-02063-6_5)
- [Google Research: Adaptive mixing of auxiliary losses in supervised learning](https://research.google/pubs/pub51874/)
- [OpenAI: Multimodal Neurons in Artificial Neural Networks](https://openai.com/blog/multimodal-neurons/)
- [OpenAI: DALL·E: Creating Images from Text](https://openai.com/blog/dall-e/)
- [OpenAI: CLIP: Connecting Text and Images](https://openai.com/blog/clip/)
- [OpenAI: Image GPT](https://openai.com/blog/image-gpt/)
- [OpenAI: Jukebox](https://openai.com/blog/jukebox/)
- [OpenAI: Solving Rubik’s Cube with a Robot Hand](https://openai.com/blog/solving-rubiks-cube/)
- [OpenAI: Multimodal Neurons in Artificial Neural Networks](https://openai.com/blog/multimodal-neurons/)
- [OpenAI: CLIP: Connecting Text and Images](https://openai.com/blog/clip/)
- [OpenAI: Image GPT](https://openai.com/blog/image-gpt/)
- [OpenAI: MuseNet](https://openai.com/blog/musenet/)
- [OpenAI: Emergent Tool Use from Multi-Agent Interaction](https://openai.com/blog/emergent-tool-use/)

### github
- [DistilKoBiLSTM](https://github.com/gyunggyung/DistilKoBiLSTM)
- [Donut: Document Understanding Transformer](https://github.com/clovaai/donut)
- [The RWKV Language Model (and my LM tricks)](https://github.com/BlinkDL/RWKV-LM)

### youtube
- [Study Playlist](https://youtube.com/playlist?list=PLsmJteXozP3oHVB5TCrXEcrfQnInMxkoT)
- [Improving Language Models by Retrieving from Trillions of Tokens | NLP Journal Club](https://youtu.be/-cnujwUDseU)
- [ECMLPKDD2021: WuDao: Pretrain the World, Keynote speaker talk by Jie Tang](https://youtu.be/D71zxGRhuxE)
- [StrictlyVC in conversation with Sam Altman, part two (OpenAI)](https://youtu.be/ebjkD1Om4uw)
- [Are Bigger Language Models Better? | DeepMind Gopher and RETRO](https://youtu.be/IaltsI1BCro)
- [The Illustrated Retrieval Transformer](https://youtu.be/sMPq4cVS4kg)

### other
- [CS224U: Natural Language Understandin](http://web.stanford.edu/class/cs224u/)
- [Gen-1: The Next Step Forward for Generative AI](https://research.runwayml.com/gen1)
- [DIFF-SVC FOR VOCAL SYNTH USERS](https://docs.google.com/document/u/0/d/1nA3PfQ-BooUpjCYErU-BHYvg2_NazAYJ0mvvmcjG40o/mobilebasic)
- [Chat GPT detector by ZeroGPT: detect OpenAI text](https://www.zerogpt.com/)

## 참여 인원 소개 
23년 3월 기준, 20명 정도 더 많은 분들이 있습니다. 합류를 원하시면 간단한 소개와 newhiwoong@gmail.com 으로 연락주세요.

1. 염기웅: 저는 여러분을 모으고 프로메우스와 바드의 꿈이라는 책을 쓰는 염기웅입니다. LLM, Dialogue Distillation, Knowledge Distillation에 관심과 지식이 있습니다! 경량화, 서빙, 멀티모달, 멀티태스크에도 관심이 있습니다. newhiwoong@gmail.com https://github.com/gyunggyung
2. 강수진: 안녕하세요. 경량화, MLOps, 사업화 관심있습니다. 현재 생성 AI 기반 창업 준비 중이며, TTS와 한국어 NLG 연구 경험이 있습니다. https://www.linkedin.com/in/ellie-kang7
3. 박상준: 스타트업 ML 엔지니어로 일하다 휴직 후 성균관대 학부생으로 NLP 연구를 하고 있습니다.
4. 이현제: 삼성SDS에서 자연어처리를 연구하고 있습니다. Instruction fine-tuning, Sentence Representation 쪽에 관심이 있습니다. oglee815@gmail.com 
5. 김기현: SKTelecom에서 LLM을 활용한 대화모델링을 연구/개발하고 있습니다 -- [Github link](https://github.com/kh-kim/)
6. 이광희: VIVE STUDIOS에서 CTO를 맡고 있는 이광희입니다. Generative AI, LLM등을 활용하여 Virtual Production, Virtual Human을 포함한 컨텐츠 저작 도구 서비스화에 관심이 있습니다. lkwanghee@gmail.com


